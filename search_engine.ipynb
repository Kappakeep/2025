{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Προεπεξεργασία\n",
    "Εδώ ειναι η συνάρτηση της προεπεξεργασίας του query (ερωτήματος)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing setup\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "def preprocess_query(query):\n",
    "    \"\"\"Preprocess the query for search.\"\"\"\n",
    "    # Tokenize and remove punctuation, digits, and lowercase everything\n",
    "    tokens = word_tokenize(query.lower())\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    return tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean Retrieval\n",
    "Παρακάτω είναι η υλοποίηση του αλγορίθμου αναζήτησης Boolean Retrieval. Σκοπός της συνάρτησης ειναι να λάβει μια λίστα από λέξεις-κλειδιά απο ένα ερώτημα αναζήτησης και να εφαρμόσει τους λογικούς τελεστές και να επιστρέψει το σύνολο των εγγράφων που ταιριάζουν με το ερώτημα. Οι παράμετροι έιναι οι:\n",
    "query_tokens: Μια λίστα από λέξεις (tokens) του ερωτήματος.\n",
    "inverted_index: Ένα λεξικό που αντιστοιχεί σε λέξεις (όρους) σε σύνολα εγγράφων στα οποία εμφανίζονται.\n",
    "\n",
    "Ορίζει τελεστές, αρχικοποιεί στοίβα, επεξεργάζεται κάθε token, ελέγχει για τελεστές, και επεξεργάζεται λέξεις.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolean_retrieval(query_tokens, inverted_index):\n",
    "    \"\"\"Boolean retrieval (supports AND, OR, NOT).\"\"\"\n",
    "    operators = {\"AND\", \"OR\", \"NOT\"}\n",
    "    stack = []\n",
    "\n",
    "    # Για να αποθηκεύσουμε τους τίτλους που βρέθηκαν\n",
    "    titles_found = set()\n",
    "\n",
    "    for token in query_tokens:\n",
    "\n",
    "        if token.upper() in operators:\n",
    "\n",
    "            # Handle AND operation\n",
    "            if token.upper() == \"AND\":\n",
    "                set2 = stack.pop() if stack else set()\n",
    "                set1 = stack.pop() if stack else set()\n",
    "                stack.append(set1 & set2)\n",
    "\n",
    "            # Handle OR operation\n",
    "            elif token.upper() == \"OR\":\n",
    "                set2 = stack.pop() if stack else set()\n",
    "                set1 = stack.pop() if stack else set()\n",
    "                stack.append(set1 | set2)\n",
    "\n",
    "            # Handle NOT operation\n",
    "            elif token.upper() == \"NOT\":\n",
    "                set1 = stack.pop() if stack else set()\n",
    "                all_docs = set(inverted_index.keys())\n",
    "                stack.append(all_docs - set1)\n",
    "\n",
    "        else:\n",
    "            # Αν η λέξη δεν είναι operator, τότε είναι λέξη για αναζήτηση στο inverted index\n",
    "            term_docs = inverted_index.get(token, set())\n",
    "\n",
    "            # Ενημερώνουμε τη λίστα των τίτλων που βρέθηκαν\n",
    "            titles_found.update(term_docs)\n",
    "            stack.append(term_docs)\n",
    "\n",
    "    # Επιστρέφουμε τη λίστα τίτλων που βρέθηκαν\n",
    "    result_titles = list(titles_found)\n",
    "    return result_titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF\n",
    "Η συνάρτηση compute_tfidf_ranking() χρησιμοποιεί την τεχνική TF-IDF (Term Frequency - Inverse Document Frequency) για να κατατάξει τα έγγραφα βάσει της σημασίας τους σε σχέση με το ερώτημα. \n",
    "Παράμετροι: \n",
    "query_tokens: Μια λίστα με τις λέξεις (tokens) του ερωτήματος που θέλουμε να αναζητήσουμε.\n",
    "documents: Μια λίστα από έγγραφα, όπου κάθε έγγραφο είναι ένα λεξικό που περιέχει τουλάχιστον το τίτλο του ('title') και το επεξεργασμένο περιεχόμενό του ('processed_content').\n",
    "Αρχικοποίηση του TfidfVectorizer ο οποίος είναι ένα εργαλείο από τη βιβλιοθήκη scikit-learn που μετατρέπει τα έγγραφα σε διανύσματα TF-IDF.\n",
    "Εξαγωγή τίτλων και περιεχομένων από τα έγγραφα, υπολογισμός του πίνακα TF-IDF ο οποίος περιέχει τα TF-IDF διανύσματα όλων των εγγράφων.\n",
    "Μετατροπή του ερωτήματος σε διανύσμα TF-IDF, υπολογισμός των σκορ, ταξινόμηση και επιστροφή των εγγράφων."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def compute_tfidf_ranking(query_tokens, documents):\n",
    "    \"\"\"Rank documents using TF-IDF.\"\"\"\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    doc_titles = [doc['title'] for doc in documents]\n",
    "    doc_contents = [doc['processed_content'] for doc in documents]\n",
    "\n",
    "    tfidf_matrix = vectorizer.fit_transform(doc_contents)\n",
    "    query_vector = vectorizer.transform([\" \".join(query_tokens)])\n",
    "\n",
    "    scores = (tfidf_matrix @ query_vector.T).toarray().flatten()\n",
    "\n",
    "    ranked_docs = sorted(\n",
    "        [(doc_titles[i], scores[i]) for i in range(len(doc_titles))],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    return ranked_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BM25OKAPI\n",
    "Η συνάρτηση compute_bm25_ranking() χρησιμοποιεί τον αλγόριθμο BM25 για να κατατάξει τα έγγραφα.\n",
    "Παράμετροι ίδιοι με τον TF-IDF. \n",
    "Η υλοποίηση αποτελείται από:\n",
    "Εξαγωγή των περιεχομένων των εγγράφων, δημιουργία του μοντέλου BM25, υπολογισμός των σκορ BM25, ταξινόμηση των εγγράφων με βάση τα σκορ, επιστροφή των καταταγμένων εγγράφων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_bm25_ranking(query_tokens, documents):\n",
    "    \"\"\"Rank documents using BM25.\"\"\"\n",
    "    doc_contents = [doc['processed_content'].split() for doc in documents]\n",
    "    bm25 = BM25Okapi(doc_contents)\n",
    "    scores = bm25.get_scores(query_tokens)\n",
    "\n",
    "    ranked_docs = sorted(\n",
    "        [(documents[i]['title'], scores[i]) for i in range(len(documents))],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    return ranked_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Space Model (VSM)\n",
    "Η συνάρτηση compute_vsm_ranking() χρησιμοποιεί το Vector Space Model (VSM) για να κατατάξει τα έγγραφα με βάση την ομοιότητα τους με το ερώτημα, χρησιμοποιώντας τον cosine similarity. Οι παράμετροι παραμένουν ίδιοι, όμως με την πρόσθεση του inverted_index ο οποίος είναι ένας αντίστροφος δείκτης που καταγράφει σε ποιά έγγραφα εμφανίζονται οι λέξεις του εγγράφου.\n",
    "Η υλοποίηση αποτελείται από:\n",
    "Υπολογισμός Term Frequency (TF), Υπολογισμός Inverse Document Frequency (IDF), Υπολογισμός των βαρών TF-IDF για κάθε έγγραφο, Υπολογισμός των βαρών TF-IDF για το ερώτημα, υπολογισμός cosine similarity, ταξινόμηση των εγγράφων"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_vsm_ranking(query_tokens, documents, inverted_index):\n",
    "    \"\"\"Rank documents using the Vector Space Model (cosine similarity).\"\"\"\n",
    "    # Step 1: Calculate term frequency (TF)\n",
    "    tf = defaultdict(Counter)\n",
    "    doc_lengths = defaultdict(int)\n",
    "\n",
    "    for doc_id, doc in enumerate(documents):\n",
    "        tokens = doc['processed_content'].split()\n",
    "        for word in tokens:\n",
    "            tf[doc_id][word] += 1\n",
    "            doc_lengths[doc_id] += 1\n",
    "\n",
    "    # Step 2: Calculate inverse document frequency (IDF)\n",
    "    idf = {}\n",
    "    total_docs = len(documents)\n",
    "    for word in inverted_index:\n",
    "        idf[word] = math.log(total_docs / (1 + len(inverted_index[word])))  # Added smoothing to avoid division by zero\n",
    "\n",
    "    # Step 3: Calculate TF-IDF weights for documents\n",
    "    tfidf_weights = defaultdict(dict)\n",
    "    for doc_id in tf:\n",
    "        for word, freq in tf[doc_id].items():\n",
    "            tfidf_weights[doc_id][word] = (freq / doc_lengths[doc_id]) * idf.get(word, 0)\n",
    "\n",
    "    # Step 4: Calculate TF-IDF weights for the query\n",
    "    query_tf = Counter(query_tokens)\n",
    "    query_length = sum(query_tf.values())\n",
    "    query_weights = {word: (query_tf[word] / query_length) * idf.get(word, 0) for word in query_tf}\n",
    "\n",
    "    # Step 5: Compute cosine similarity\n",
    "    scores = defaultdict(float)\n",
    "    for doc_id, weights in tfidf_weights.items():\n",
    "        dot_product = sum(weights[word] * query_weights.get(word, 0) for word in query_weights if word in weights)\n",
    "        doc_norm = math.sqrt(sum(value ** 2 for value in weights.values()))\n",
    "        query_norm = math.sqrt(sum(value ** 2 for value in query_weights.values()))\n",
    "        if doc_norm * query_norm != 0:  # Avoid division by zero\n",
    "            scores[doc_id] = dot_product / (doc_norm * query_norm)\n",
    "\n",
    "    # Rank documents by score\n",
    "    ranked_docs = sorted(\n",
    "        [(documents[doc_id]['title'], score) for doc_id, score in scores.items()],\n",
    "        key=lambda x: x[1],\n",
    "        reverse=True\n",
    "    )\n",
    "    return ranked_docs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Εδώ απλά φορτώνονται τα .json αρχεία που χρειαζόμαστε.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the inverted index and preprocessed articles\n",
    "with open(\"inverted_index.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    inverted_index = json.load(f)\n",
    "\n",
    "with open(\"preprocessed_wikipedia_articles.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    documents = json.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Παρακάτω είναι η υλοποίηση του συντονιστή της μηχανής αναζήτησης."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_engine(query, method=\"boolean\"):\n",
    "    \"\"\"Search engine supporting Boolean, TF-IDF, BM25, and VSM.\"\"\"\n",
    "    query_tokens = preprocess_query(query)\n",
    "\n",
    "    if method == \"boolean\":\n",
    "        result_titles = boolean_retrieval(query_tokens, inverted_index)\n",
    "        results = [doc for doc in documents if doc['title'].lower() in [title.lower() for title in result_titles]]\n",
    "        return [doc for doc in documents if doc['title'] in result_titles]\n",
    "       \n",
    "    elif method == \"tfidf\":\n",
    "        ranked_docs = compute_tfidf_ranking(query_tokens, documents)\n",
    "        return ranked_docs\n",
    "\n",
    "    elif method == \"bm25\":\n",
    "        ranked_docs = compute_bm25_ranking(query_tokens, documents)\n",
    "        return ranked_docs\n",
    "\n",
    "    elif method == \"vsm\":\n",
    "        ranked_docs = compute_vsm_ranking(query_tokens, documents, inverted_index)\n",
    "        return ranked_docs\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid method. Choose from 'boolean', 'tfidf', 'bm25', or 'vsm'.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τέλος, είναι το GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the search engine!\n",
      "\n",
      "\n",
      "Results (100 found):\n",
      "- Neural network (machine learning) (score: 0.3248)\n",
      "- Deep learning (score: 0.2640)\n",
      "- Generative audio (score: 0.0963)\n",
      "- Artificial intelligence (score: 0.0932)\n",
      "- Machine learning (score: 0.0872)\n",
      "- History of artificial intelligence (score: 0.0787)\n",
      "- Machine learning in bioinformatics (score: 0.0708)\n",
      "- Symbolic artificial intelligence (score: 0.0693)\n",
      "- Natural language processing (score: 0.0682)\n",
      "- Bayesian network (score: 0.0681)\n",
      "- Computational creativity (score: 0.0566)\n",
      "- Applications of artificial intelligence (score: 0.0532)\n",
      "- Applications of artificial intelligence (score: 0.0532)\n",
      "- Applications of artificial intelligence (score: 0.0532)\n",
      "- Neuroscience (score: 0.0501)\n",
      "- Machine learning in earth sciences (score: 0.0450)\n",
      "- Generative artificial intelligence (score: 0.0410)\n",
      "- AI winter (score: 0.0321)\n",
      "- Recommender system (score: 0.0265)\n",
      "- Computer vision (score: 0.0246)\n",
      "- Glossary of artificial intelligence (score: 0.0242)\n",
      "- Ethics of artificial intelligence (score: 0.0230)\n",
      "- Artificial consciousness (score: 0.0227)\n",
      "- Transformer (deep learning architecture) (score: 0.0227)\n",
      "- Artificial intelligence in healthcare (score: 0.0210)\n",
      "- Artificial intelligence art (score: 0.0210)\n",
      "- Artificial intelligence art (score: 0.0210)\n",
      "- Music and artificial intelligence (score: 0.0178)\n",
      "- Deepfake (score: 0.0162)\n",
      "- AI safety (score: 0.0155)\n",
      "- AI boom (score: 0.0153)\n",
      "- Machine translation (score: 0.0128)\n",
      "- Artificial general intelligence (score: 0.0117)\n",
      "- AI alignment (score: 0.0093)\n",
      "- Operations research (score: 0.0092)\n",
      "- Computer science (score: 0.0087)\n",
      "- Automated planning and scheduling (score: 0.0085)\n",
      "- Intelligent agent (score: 0.0084)\n",
      "- Mathematical optimization (score: 0.0083)\n",
      "- Evolutionary algorithm (score: 0.0080)\n",
      "- Psychology (score: 0.0078)\n",
      "- Artificial intelligence arms race (score: 0.0078)\n",
      "- Philosophy of artificial intelligence (score: 0.0078)\n",
      "- Computer (score: 0.0075)\n",
      "- Knowledge representation and reasoning (score: 0.0062)\n",
      "- Knowledge representation and reasoning (score: 0.0062)\n",
      "- Virtual assistant (score: 0.0060)\n",
      "- AI takeover (score: 0.0059)\n",
      "- Artificial intelligence systems integration (score: 0.0059)\n",
      "- Vehicular automation (score: 0.0046)\n",
      "- Database (score: 0.0045)\n",
      "- Machine perception (score: 0.0045)\n",
      "- Netflix (score: 0.0043)\n",
      "- Statistics (score: 0.0042)\n",
      "- Existential risk from artificial intelligence (score: 0.0039)\n",
      "- Existential risk from artificial intelligence (score: 0.0039)\n",
      "- Robotics (score: 0.0036)\n",
      "- Chinese room (score: 0.0034)\n",
      "- Siri (score: 0.0028)\n",
      "- Google Search (score: 0.0028)\n",
      "- YouTube (score: 0.0026)\n",
      "- Chess (score: 0.0026)\n",
      "- Waymo (score: 0.0025)\n",
      "- Amazon (company) (score: 0.0016)\n",
      "- Ontology (information science) (score: 0.0011)\n",
      "- Regulation of artificial intelligence (score: 0.0011)\n",
      "- ChatGPT (score: 0.0008)\n",
      "- Ai (score: 0.0000)\n",
      "- Artificial intelligence (disambiguation) (score: 0.0000)\n",
      "- General game playing (score: 0.0000)\n",
      "- Hybrid intelligent system (score: 0.0000)\n",
      "- Artificial intelligence in government (score: 0.0000)\n",
      "- Artificial intelligence in mental health (score: 0.0000)\n",
      "- Artificial intelligence in industry (score: 0.0000)\n",
      "- Machine learning in physics (score: 0.0000)\n",
      "- List of artificial intelligence projects (score: 0.0000)\n",
      "- Friendly artificial intelligence (score: 0.0000)\n",
      "- Turing test (score: 0.0000)\n",
      "- Timeline of artificial intelligence (score: 0.0000)\n",
      "- Progress in artificial intelligence (score: 0.0000)\n",
      "- Intelligence (score: 0.0000)\n",
      "- Software (score: 0.0000)\n",
      "- Search engine (score: 0.0000)\n",
      "- Google Assistant (score: 0.0000)\n",
      "- Superintelligence (score: 0.0000)\n",
      "- Strategy game (score: 0.0000)\n",
      "- Go (game) (score: 0.0000)\n",
      "- AI effect (score: 0.0000)\n",
      "- Automated reasoning (score: 0.0000)\n",
      "- State space search (score: 0.0000)\n",
      "- Logic (score: 0.0000)\n",
      "- Economics (score: 0.0000)\n",
      "- Linguistics (score: 0.0000)\n",
      "- AI aftermath scenarios (score: 0.0000)\n",
      "- Deductive reasoning (score: 0.0000)\n",
      "- Probability (score: 0.0000)\n",
      "- Knowledge engineering (score: 0.0000)\n",
      "- Knowledge base (score: 0.0000)\n",
      "- Default logic (score: 0.0000)\n",
      "- Knowledge acquisition (score: 0.0000)\n",
      "Exiting the search engine.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Welcome to the search engine!\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_query = input(\"Enter your query (or 'exit' to exit): \")\n",
    "        if user_query.lower() == \"exit\":\n",
    "            print(\"Exiting the search engine.\")\n",
    "            break\n",
    "\n",
    "        method = input(\"Choose search method (boolean, tfidf, bm25): \").lower()\n",
    "        \n",
    "        try:\n",
    "            # Αμέσως επεξεργαζόμαστε την αναζήτηση και παίρνουμε τα αποτελέσματα\n",
    "            results = search_engine(user_query, method)\n",
    "            \n",
    "            # Εκτύπωση των αποτελεσμάτων ως λίστα\n",
    "            print(f\"\\nResults ({len(results)} found):\")\n",
    "            titles = []\n",
    "            if method == \"boolean\":\n",
    "                # Όταν είναι boolean, παίρνουμε τους τίτλους από τα αποτελέσματα\n",
    "                for result in results:\n",
    "                    titles.append(result['title'])\n",
    "            else:\n",
    "                # Για άλλες μεθόδους, παίρνουμε τίτλους και σκορ\n",
    "                for title, score in results:\n",
    "                    titles.append(f\"{title} (score: {score:.4f})\")\n",
    "\n",
    "            # Εκτύπωση της λίστας με τους τίτλους\n",
    "            print(\"\\n\".join([f\"- {title}\" for title in titles]))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
